<div align="center">
  <p align="center">
    <h1> 🧠🖥️ Lomina </h1>
  </p>
  <p>
    Intelligent Assistant for Enterprise Knowledge Management
  </p>
  
  [![En Español](https://img.shields.io/badge/README-Spanish-blue?style=for-the-badge)](./README.md)

</div>

## 🎯 Project Objective
Design and develop a web application that acts as an internal intelligent assistant for companies. It should be able to answer questions about internal documentation, policies, manuals, and other resources using a locally hosted large language model (LLM). The architecture must be based on microservices, use Angular for the frontend, and be fully deployed on a Kubernetes cluster.

## 📘 Problem Description
Companies accumulate large amounts of documents, manuals, and policies that often become difficult for employees to consult. Traditional search engines are not efficient at answering complex or contextual questions. The company’s management has decided to implement a modern solution based on an intelligent assistant that runs entirely on local infrastructure for privacy and confidentiality reasons.

## 🧱 Technical Requirements

### 🖼️ 1. Frontend (Angular)
A simple interface where the user can:

- Ask questions in natural language.
- View responses generated by the LLM.
- View the history of questions and answers.

### 🗃️ 2. Backend and Microservices

- **API Gateway:** Receives requests from the frontend and orchestrates calls to other microservices.
- **LLM Service:** Encapsulates a model like LLaMA 3 or Mistral using a local tool such as Ollama or llama.cpp.
- **Document and Indexing Service:**  
  Allows uploading and preprocessing of business documents (PDF, DOCX, etc.).
- **Authentication Service:** Access via credentials.
- Uses embeddings to index documents (optional).

### 🎢 3. Kubernetes Deployment
All services must be containerized and deployed in Kubernetes.

Includes:
- Deployment, Service, and Ingress YAML files.
- Configuration of persistent volumes for the LLM and document storage.
- Scalability: microservices must support horizontal scaling.

## 🧪 Milestones

- [ ] Proper separation of concerns between microservices.
- [ ] LLM's ability to answer real-world questions.
- [ ] Functional deployment in Kubernetes.
- [ ] Quality of the user interface.
- [ ] Use of best practices:
  - [ ]  Clean code.
  - [ ]  Documentation.
  - [ ]  CI/CD.
